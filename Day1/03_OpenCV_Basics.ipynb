{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ec0c791",
   "metadata": {},
   "source": [
    "# Day 1: OpenCV Basics\n",
    "## CV Bootcamp 2024\n",
    "\n",
    "OpenCV is the most widely used library for real-time computer vision with 2500+ optimized algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf993de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2063674",
   "metadata": {},
   "source": [
    "## 1. Reading and Writing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23443863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample image for demonstration\n",
    "sample_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "cv2.imwrite('sample.jpg', sample_image)\n",
    "\n",
    "# Read image (returns BGR format!)\n",
    "image = cv2.imread('sample.jpg')\n",
    "\n",
    "# Check if loaded successfully\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image\")\n",
    "else:\n",
    "    print(f\"Image loaded: {image.shape}\")\n",
    "    print(f\"Data type: {image.dtype}\")\n",
    "    print(f\"Total pixels: {image.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read modes\n",
    "gray = cv2.imread('sample.jpg', cv2.IMREAD_GRAYSCALE)  # Grayscale\n",
    "unchanged = cv2.imread('sample.jpg', cv2.IMREAD_UNCHANGED)  # With alpha\n",
    "\n",
    "print(f\"Grayscale shape: {gray.shape}\")\n",
    "print(f\"Unchanged shape: {unchanged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a01f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write image with quality settings\n",
    "cv2.imwrite('output.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, 95])\n",
    "cv2.imwrite('output.png', image, [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
    "print(\"Images saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b50edd",
   "metadata": {},
   "source": [
    "## 2. Color Space Conversions\n",
    "\n",
    "**IMPORTANT:** OpenCV uses BGR, not RGB!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be33a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGR to RGB (for matplotlib display)\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# BGR to Grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# BGR to HSV (Hue, Saturation, Value)\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# BGR to LAB\n",
    "lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "print(f\"Original BGR: {image.shape}\")\n",
    "print(f\"Grayscale: {gray.shape}\")\n",
    "print(f\"HSV: {hsv.shape}\")\n",
    "print(f\"LAB: {lab.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].imshow(rgb)\n",
    "axes[0, 0].set_title('RGB')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(gray, cmap='gray')\n",
    "axes[0, 1].set_title('Grayscale')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB))\n",
    "axes[1, 0].set_title('HSV')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(lab, cv2.COLOR_LAB2RGB))\n",
    "axes[1, 1].set_title('LAB')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c71f116",
   "metadata": {},
   "source": [
    "## 3. Resizing and Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = image.shape[:2]\n",
    "\n",
    "# Resize to specific dimensions (width, height)\n",
    "resized = cv2.resize(image, (320, 240))\n",
    "\n",
    "# Resize with scale factor\n",
    "scaled_down = cv2.resize(image, None, fx=0.5, fy=0.5)\n",
    "scaled_up = cv2.resize(image, None, fx=2.0, fy=2.0)\n",
    "\n",
    "print(f\"Original: {image.shape}\")\n",
    "print(f\"Resized: {resized.shape}\")\n",
    "print(f\"Scaled down (0.5x): {scaled_down.shape}\")\n",
    "print(f\"Scaled up (2.0x): {scaled_up.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f54005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize maintaining aspect ratio\n",
    "def resize_with_aspect_ratio(img, target_width=None, target_height=None):\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    if target_width is not None:\n",
    "        aspect = h / w\n",
    "        new_h = int(target_width * aspect)\n",
    "        return cv2.resize(img, (target_width, new_h))\n",
    "    \n",
    "    if target_height is not None:\n",
    "        aspect = w / h\n",
    "        new_w = int(target_height * aspect)\n",
    "        return cv2.resize(img, (new_w, target_height))\n",
    "    \n",
    "    return img\n",
    "\n",
    "resized_aspect = resize_with_aspect_ratio(image, target_width=400)\n",
    "print(f\"Resized with aspect ratio: {resized_aspect.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d1966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation methods\n",
    "upscaled_nearest = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_NEAREST)\n",
    "upscaled_linear = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)\n",
    "upscaled_cubic = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "print(\"Interpolation methods:\")\n",
    "print(\"- INTER_NEAREST: Fastest, lowest quality\")\n",
    "print(\"- INTER_LINEAR: Default, good balance\")\n",
    "print(\"- INTER_CUBIC: Slower, better quality\")\n",
    "print(\"- INTER_LANCZOS4: Best quality, slowest\")\n",
    "print(\"- INTER_AREA: Best for downscaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1405d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping (using array slicing)\n",
    "# Format: image[y1:y2, x1:x2]\n",
    "\n",
    "# Crop top-left 100x100\n",
    "crop_tl = image[0:100, 0:100]\n",
    "\n",
    "# Crop center region\n",
    "center_x, center_y = w // 2, h // 2\n",
    "crop_size = 200\n",
    "center_crop = image[\n",
    "    center_y - crop_size//2 : center_y + crop_size//2,\n",
    "    center_x - crop_size//2 : center_x + crop_size//2\n",
    "]\n",
    "\n",
    "# Crop bottom-right quarter\n",
    "crop_br = image[h//2:, w//2:]\n",
    "\n",
    "print(f\"Top-left crop: {crop_tl.shape}\")\n",
    "print(f\"Center crop: {center_crop.shape}\")\n",
    "print(f\"Bottom-right crop: {crop_br.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf73c23",
   "metadata": {},
   "source": [
    "## 4. Blurring Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f576f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Gaussian Blur - Most common, good for noise reduction\n",
    "blur_gaussian = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "blur_strong = cv2.GaussianBlur(image, (15, 15), 0)\n",
    "\n",
    "# 2. Median Blur - Best for salt-and-pepper noise\n",
    "blur_median = cv2.medianBlur(image, 5)\n",
    "\n",
    "# 3. Average Blur - Simple averaging\n",
    "blur_average = cv2.blur(image, (5, 5))\n",
    "\n",
    "# 4. Bilateral Filter - Smooths while preserving edges\n",
    "blur_bilateral = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "\n",
    "print(\"Blur methods applied successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c0b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "images = [image, blur_gaussian, blur_median, blur_bilateral]\n",
    "titles = ['Original', 'Gaussian', 'Median', 'Bilateral']\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "for img, title, ax in zip(images, titles, axes):\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad4be9",
   "metadata": {},
   "source": [
    "## 5. Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur first (reduces noise)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Canny edge detection\n",
    "edges = cv2.Canny(blurred, threshold1=50, threshold2=150)\n",
    "\n",
    "# Try different thresholds\n",
    "edges_sensitive = cv2.Canny(blurred, 30, 100)   # More edges\n",
    "edges_strict = cv2.Canny(blurred, 100, 200)     # Fewer edges\n",
    "\n",
    "print(\"Edge detection completed\")\n",
    "print(f\"Edges shape: {edges.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62556898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic threshold calculation\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    \"\"\"Automatically determine Canny thresholds\"\"\"\n",
    "    median_val = np.median(image)\n",
    "    lower = int(max(0, (1.0 - sigma) * median_val))\n",
    "    upper = int(min(255, (1.0 + sigma) * median_val))\n",
    "    return cv2.Canny(image, lower, upper)\n",
    "\n",
    "edges_auto = auto_canny(blurred)\n",
    "print(f\"Auto edges calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615660ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "axes[0].imshow(gray, cmap='gray')\n",
    "axes[0].set_title('Original Grayscale')\n",
    "\n",
    "axes[1].imshow(blurred, cmap='gray')\n",
    "axes[1].set_title('Blurred')\n",
    "\n",
    "axes[2].imshow(edges, cmap='gray')\n",
    "axes[2].set_title('Canny (50, 150)')\n",
    "\n",
    "axes[3].imshow(edges_sensitive, cmap='gray')\n",
    "axes[3].set_title('Sensitive (30, 100)')\n",
    "\n",
    "axes[4].imshow(edges_strict, cmap='gray')\n",
    "axes[4].set_title('Strict (100, 200)')\n",
    "\n",
    "axes[5].imshow(edges_auto, cmap='gray')\n",
    "axes[5].set_title('Auto Threshold')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b629ad3",
   "metadata": {},
   "source": [
    "## 6. Complete Edge Detection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be86d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges(image_path, low_threshold=50, high_threshold=150, blur_kernel=5):\n",
    "    \"\"\"\n",
    "    Apply Canny edge detection to an image with preprocessing.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to input image\n",
    "        low_threshold: Lower threshold for Canny\n",
    "        high_threshold: Upper threshold for Canny\n",
    "        blur_kernel: Gaussian blur kernel size (must be odd)\n",
    "    \n",
    "    Returns:\n",
    "        original_image_rgb, edges_image\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if image is None:\n",
    "        print(f'Error: Could not load {image_path}')\n",
    "        return None, None\n",
    "    \n",
    "    # Convert to RGB for display\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (blur_kernel, blur_kernel), 0)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(blurred, low_threshold, high_threshold)\n",
    "    \n",
    "    return image_rgb, edges\n",
    "\n",
    "# Test the function\n",
    "original, edges = detect_edges('sample.jpg')\n",
    "\n",
    "if original is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "    \n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(edges, cmap='gray')\n",
    "    axes[1].set_title('Edge Detection')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3c1ab3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned:\n",
    "- ✓ Reading and writing images with OpenCV\n",
    "- ✓ Color space conversions (BGR ↔ RGB, Grayscale, HSV, LAB)\n",
    "- ✓ Resizing with different interpolation methods\n",
    "- ✓ Cropping using array slicing\n",
    "- ✓ Blurring techniques (Gaussian, Median, Bilateral)\n",
    "- ✓ Canny edge detection with auto-thresholding\n",
    "- ✓ Building complete image processing pipelines\n",
    "\n",
    "**Key Takeaway:** OpenCV uses BGR format - always convert to RGB for matplotlib display!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
