{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8367f5",
   "metadata": {},
   "source": [
    "# Day 3: Transfer Learning\n",
    "## CV Bootcamp 2024\n",
    "\n",
    "Leverage pretrained models for faster training and better results!\n",
    "\n",
    "**Why Transfer Learning?**\n",
    "- Train in minutes instead of hours\n",
    "- Need only 100s of images instead of 1000s\n",
    "- Achieve state-of-the-art results\n",
    "- Leverage knowledge from ImageNet (1.4M images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a72b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d11c78d",
   "metadata": {},
   "source": [
    "## 1. Why Transfer Learning Works\n",
    "\n",
    "### The Key Insight\n",
    "\n",
    "Early layers of CNNs learn **generic features** (edges, textures, colors) that are useful for ALL vision tasks.\n",
    "\n",
    "Only the final layers learn **task-specific features**.\n",
    "\n",
    "**Strategy:**\n",
    "1. Use a model pretrained on ImageNet (learned generic features)\n",
    "2. Freeze early layers (keep the generic features)\n",
    "3. Only train final layers for your specific task\n",
    "\n",
    "**When to use:**\n",
    "- ‚úì Limited training data\n",
    "- ‚úì Similar task to ImageNet (object recognition)\n",
    "- ‚úì Want quick baseline\n",
    "- ‚úì Limited compute resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97a4659",
   "metadata": {},
   "source": [
    "## 2. Load Pretrained ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d700c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ResNet18\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "print('ResNet18 architecture:')\n",
    "print(model)\n",
    "\n",
    "print(f'\\nFinal layer input features: {model.fc.in_features}')\n",
    "print(f'Final layer output features: {model.fc.out_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arch_understanding",
   "metadata": {},
   "source": [
    "## 3. Understanding ResNet Architecture\n",
    "\n",
    "### ResNet's Innovation: Skip Connections\n",
    "\n",
    "```\n",
    "      input (x)\n",
    "         |\n",
    "   [conv-relu-conv]  ‚Üê learns F(x)\n",
    "         |\n",
    "         +  <--------- skip connection (adds x)\n",
    "         |\n",
    "      output = F(x) + x\n",
    "```\n",
    "\n",
    "**Why it works:**\n",
    "- Gradients flow directly through skip connections\n",
    "- Enables training very deep networks (100+ layers)\n",
    "- If a layer isn't helpful, it can learn F(x) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arch_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine ResNet layers\n",
    "print(\"ResNet18 structure:\")\n",
    "print(\"=\"*50)\n",
    "for name, module in model.named_children():\n",
    "    print(f\"{name:15s}: {module.__class__.__name__}\")\n",
    "\n",
    "print(\"\\nResidual blocks in layer1:\")\n",
    "for i, block in enumerate(model.layer1):\n",
    "    print(f\"  Block {i}: {block}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594d456",
   "metadata": {},
   "source": [
    "## 4. Freeze Pretrained Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e1ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for binary classification (Cat vs Dog)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print('Modified model final layer:')\n",
    "print(model.fc)\n",
    "\n",
    "# Count trainable vs total parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'\\nTotal parameters: {total_params:,}')\n",
    "print(f'Trainable parameters: {trainable_params:,}')\n",
    "print(f'Frozen parameters: {total_params - trainable_params:,}')\n",
    "print(f'\\n% trainable: {100*trainable_params/total_params:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53426e2e",
   "metadata": {},
   "source": [
    "## 5. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only optimize parameters of final layer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "print('Optimizer configured to train only final layer')\n",
    "print(f'Learning rate: {optimizer.param_groups[0][\"lr\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lr_scheduling",
   "metadata": {},
   "source": [
    "## 6. Learning Rate Scheduling\n",
    "\n",
    "Learning rate should decrease over time for better convergence.\n",
    "\n",
    "### Common Schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lr_examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. StepLR: Reduce LR every N epochs\n",
    "scheduler_step = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "print(\"StepLR: Multiply LR by 0.1 every 5 epochs\")\n",
    "\n",
    "# 2. ReduceLROnPlateau: Reduce when validation stops improving\n",
    "scheduler_plateau = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "print(\"ReduceLROnPlateau: Reduce LR by 0.5 if no improvement for 3 epochs\")\n",
    "\n",
    "# 3. CosineAnnealingLR: Smooth decrease\n",
    "scheduler_cosine = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "print(\"CosineAnnealingLR: Smooth decrease following cosine curve\")\n",
    "\n",
    "# Visualize schedules\n",
    "def plot_lr_schedule(scheduler, epochs=20):\n",
    "    lrs = []\n",
    "    for epoch in range(epochs):\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "        scheduler.step()\n",
    "    return lrs\n",
    "\n",
    "# Reset optimizer\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# StepLR\n",
    "optimizer.param_groups[0]['lr'] = 0.001\n",
    "sch = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "lrs = plot_lr_schedule(sch, 20)\n",
    "axes[0].plot(lrs)\n",
    "axes[0].set_title('StepLR')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Learning Rate')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Cosine\n",
    "optimizer.param_groups[0]['lr'] = 0.001\n",
    "sch = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
    "lrs = plot_lr_schedule(sch, 20)\n",
    "axes[1].plot(lrs)\n",
    "axes[1].set_title('CosineAnnealingLR')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Exponential\n",
    "optimizer.param_groups[0]['lr'] = 0.001\n",
    "sch = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "lrs = plot_lr_schedule(sch, 20)\n",
    "axes[2].plot(lrs)\n",
    "axes[2].set_title('ExponentialLR')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Reset for actual training\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ca4ab",
   "metadata": {},
   "source": [
    "## 7. Fine-Tuning Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73c6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Train only final layer (what we're doing)\n",
    "print(\"Strategy 1: Train only final layer\")\n",
    "print(\"  - Fastest\")\n",
    "print(\"  - Needs least data\")\n",
    "print(\"  - Good for similar tasks to ImageNet\\n\")\n",
    "\n",
    "# Strategy 2: Unfreeze last few layers\n",
    "def unfreeze_last_n_layers(model, n=1):\n",
    "    \"\"\"Unfreeze last n residual blocks\"\"\"\n",
    "    layers = [model.layer4, model.layer3, model.layer2, model.layer1]\n",
    "    for i in range(n):\n",
    "        for param in layers[i].parameters():\n",
    "            param.requires_grad = True\n",
    "    return model\n",
    "\n",
    "print(\"Strategy 2: Unfreeze last few layers\")\n",
    "print(\"  - More flexible\")\n",
    "print(\"  - Needs more data\")\n",
    "print(\"  - Better for different tasks\\n\")\n",
    "\n",
    "# Strategy 3: Unfreeze all with different learning rates\n",
    "print(\"Strategy 3: Different LR for different layers\")\n",
    "print(\"  - Best results\")\n",
    "print(\"  - Needs most data\")\n",
    "print(\"  - Use lower LR for early layers\")\n",
    "\n",
    "# Example of strategy 3\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = True\n",
    "# \n",
    "# optimizer = optim.Adam([\n",
    "#     {'params': model.layer4.parameters(), 'lr': 1e-4},\n",
    "#     {'params': model.layer3.parameters(), 'lr': 1e-5},\n",
    "#     {'params': model.fc.parameters(), 'lr': 1e-3}\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb861a2",
   "metadata": {},
   "source": [
    "## 8. Data Augmentation for Transfer Learning\n",
    "\n",
    "**Critical:** Use ImageNet statistics for normalization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f1a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet statistics\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Training: WITH augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# Validation/Test: NO augmentation\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "print('Transforms defined with ImageNet statistics')\n",
    "print(f'Mean: {imagenet_mean}')\n",
    "print(f'Std:  {imagenet_std}')\n",
    "print('\\n‚ö† Important: NEVER augment validation/test data!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2475ca31",
   "metadata": {},
   "source": [
    "## 9. Popular Pretrained Models\n",
    "\n",
    "PyTorch provides many pretrained models. Let's compare them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load different architectures\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "mobilenet_v2 = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "print('Available pretrained models:')\n",
    "print('- ResNet family (18, 34, 50, 101, 152)')\n",
    "print('- VGG family (16, 19)')\n",
    "print('- MobileNet v2/v3 (mobile-optimized)')\n",
    "print('- EfficientNet family (b0-b7)')\n",
    "print('- DenseNet family (121, 161, 169, 201)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e716985",
   "metadata": {},
   "source": [
    "## 10. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_compare = {\n",
    "    'ResNet18': models.resnet18(pretrained=True),\n",
    "    'ResNet50': models.resnet50(pretrained=True),\n",
    "    'MobileNetV2': models.mobilenet_v2(pretrained=True)\n",
    "}\n",
    "\n",
    "print('Model Comparison:\\n')\n",
    "print(f'{\"Model\":<15} {\"Parameters\":>12} {\"Size (MB)\":>12} {\"Use Case\"}')\n",
    "print('=' * 70)\n",
    "\n",
    "for name, model in models_to_compare.items():\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    size_mb = params * 4 / 1024 / 1024  # Assuming float32\n",
    "    \n",
    "    use_case = {\n",
    "        'ResNet18': 'Quick baseline, learning',\n",
    "        'ResNet50': 'General purpose, best accuracy',\n",
    "        'MobileNetV2': 'Mobile/edge deployment'\n",
    "    }[name]\n",
    "    \n",
    "    print(f'{name:<15} {params:>12,} {size_mb:>11.1f} {use_case}')\n",
    "\n",
    "# Speed test\n",
    "print('\\nInference Speed Test (CPU):')\n",
    "test_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "import time\n",
    "for name, model in models_to_compare.items():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        for _ in range(10):\n",
    "            _ = model(test_input)\n",
    "        elapsed = (time.time() - start) / 10\n",
    "    print(f'{name:<15}: {elapsed*1000:.1f} ms per image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choosing",
   "metadata": {},
   "source": [
    "## 11. Choosing the Right Model\n",
    "\n",
    "### Decision Guide:\n",
    "\n",
    "**For Learning/Prototyping:**\n",
    "- Use ResNet18\n",
    "- Fast to train and test\n",
    "\n",
    "**For Best Accuracy:**\n",
    "- Use ResNet50 or EfficientNet-B3\n",
    "- More parameters, better performance\n",
    "\n",
    "**For Mobile/Edge Deployment:**\n",
    "- Use MobileNetV2 or MobileNetV3\n",
    "- Optimized for speed and size\n",
    "\n",
    "**For Production with GPUs:**\n",
    "- Use ResNet50 or EfficientNet-B0\n",
    "- Good balance of speed and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example_training",
   "metadata": {},
   "source": [
    "## 12. Complete Training Example\n",
    "\n",
    "Here's how you'd train with transfer learning in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "full_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-code for complete training\n",
    "\n",
    "def train_with_transfer_learning(train_loader, val_loader, num_epochs=10):\n",
    "    \"\"\"\n",
    "    Complete transfer learning training loop\n",
    "    \"\"\"\n",
    "    # 1. Load pretrained model\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    \n",
    "    # 2. Freeze all layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # 3. Replace final layer\n",
    "    model.fc = nn.Linear(model.fc.in_features, 2)  # Binary classification\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 4. Setup training\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    # 5. Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = correct / total\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Val Acc = {val_acc*100:.2f}%')\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Training function defined!\")\n",
    "print(\"Call with: model = train_with_transfer_learning(train_loader, val_loader)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8bbfb4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned:\n",
    "- ‚úì Why transfer learning works (generic features)\n",
    "- ‚úì Loading pretrained models\n",
    "- ‚úì Freezing layers for transfer learning\n",
    "- ‚úì Replacing final layer for custom tasks\n",
    "- ‚úì Fine-tuning strategies (feature extraction vs full fine-tuning)\n",
    "- ‚úì Using ImageNet statistics\n",
    "- ‚úì Learning rate scheduling\n",
    "- ‚úì Popular model architectures and when to use them\n",
    "- ‚úì Complete training workflow\n",
    "\n",
    "**Key Takeaways:**\n",
    "1. Transfer learning dramatically reduces training time and data requirements\n",
    "2. Start with ResNet18 for prototyping\n",
    "3. Always use ImageNet statistics for normalization\n",
    "4. Use learning rate scheduling for better convergence\n",
    "5. Choose model based on your deployment constraints\n",
    "\n",
    "**Next Step:** Apply this to your Cat vs Dog assignment! üê±üê∂"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
