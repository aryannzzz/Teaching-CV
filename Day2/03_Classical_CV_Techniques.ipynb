{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c9aaeb",
   "metadata": {},
   "source": [
    "# Day 2: Classical CV Techniques\n",
    "## CV Bootcamp 2024\n",
    "\n",
    "Classical computer vision techniques that are still widely used today for feature detection, object recognition, and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee3ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create sample image\n",
    "sample = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "# Add some geometric shapes for detection\n",
    "cv2.rectangle(sample, (100, 100), (200, 200), (255, 255, 255), -1)\n",
    "cv2.circle(sample, (400, 300), 50, (255, 255, 255), -1)\n",
    "cv2.imwrite('sample_classical.jpg', sample)\n",
    "\n",
    "image = cv2.imread('sample_classical.jpg')\n",
    "print(f\"Image loaded: {image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e48f720",
   "metadata": {},
   "source": [
    "## 1. Advanced Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b7485",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 1. Sobel Edge Detection (gradient-based)\n",
    "sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)  # Horizontal edges\n",
    "sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)  # Vertical edges\n",
    "\n",
    "# Combine both directions\n",
    "sobel_combined = np.sqrt(sobelx**2 + sobely**2)\n",
    "sobel_combined = np.uint8(sobel_combined)\n",
    "\n",
    "# 2. Laplacian Edge Detection (second derivative)\n",
    "laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "laplacian = np.uint8(np.absolute(laplacian))\n",
    "\n",
    "# 3. Canny (still the best)\n",
    "canny = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "print(\"Edge detection methods applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9df095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize different edge detectors\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "axes[0].imshow(gray, cmap='gray')\n",
    "axes[0].set_title('Original Grayscale')\n",
    "\n",
    "axes[1].imshow(sobelx, cmap='gray')\n",
    "axes[1].set_title('Sobel X (Vertical Edges)')\n",
    "\n",
    "axes[2].imshow(sobely, cmap='gray')\n",
    "axes[2].set_title('Sobel Y (Horizontal Edges)')\n",
    "\n",
    "axes[3].imshow(sobel_combined, cmap='gray')\n",
    "axes[3].set_title('Sobel Combined')\n",
    "\n",
    "axes[4].imshow(laplacian, cmap='gray')\n",
    "axes[4].set_title('Laplacian')\n",
    "\n",
    "axes[5].imshow(canny, cmap='gray')\n",
    "axes[5].set_title('Canny')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8121dea8",
   "metadata": {},
   "source": [
    "## 2. Contour Detection and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to grayscale and threshold\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print(f'Found {len(contours)} contours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf975f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw all contours\n",
    "result = image.copy()\n",
    "cv2.drawContours(result, contours, -1, (0, 255, 0), 2)  # -1 means all contours\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'All Contours ({len(contours)} found)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter contours by area\n",
    "large_contours = [c for c in contours if cv2.contourArea(c) > 1000]\n",
    "print(f'Large contours (area > 1000): {len(large_contours)}')\n",
    "\n",
    "# Draw bounding boxes\n",
    "result_boxes = image.copy()\n",
    "for contour in large_contours:\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    cv2.rectangle(result_boxes, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    \n",
    "    # Get contour properties\n",
    "    area = cv2.contourArea(contour)\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    \n",
    "    # Add text\n",
    "    cv2.putText(result_boxes, f'A:{int(area)}', (x, y-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(result_boxes, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Bounding Boxes with Area')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf956a43",
   "metadata": {},
   "source": [
    "## 3. Hough Transform - Line Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image with lines\n",
    "line_image = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "cv2.line(line_image, (100, 100), (500, 100), (255, 255, 255), 2)\n",
    "cv2.line(line_image, (200, 200), (200, 400), (255, 255, 255), 2)\n",
    "cv2.line(line_image, (300, 150), (450, 350), (255, 255, 255), 2)\n",
    "\n",
    "gray_lines = cv2.cvtColor(line_image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray_lines, 50, 150)\n",
    "\n",
    "# Hough Line Transform\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50,\n",
    "                        minLineLength=50, maxLineGap=10)\n",
    "\n",
    "# Draw detected lines\n",
    "result_lines = line_image.copy()\n",
    "if lines is not None:\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(result_lines, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "    print(f'Detected {len(lines)} lines')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(line_image)\n",
    "axes[0].set_title('Original')\n",
    "axes[1].imshow(edges, cmap='gray')\n",
    "axes[1].set_title('Edges')\n",
    "axes[2].imshow(cv2.cvtColor(result_lines, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Detected Lines')\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e2953",
   "metadata": {},
   "source": [
    "## 4. Hough Transform - Circle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de61461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image with circles\n",
    "circle_image = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "cv2.circle(circle_image, (200, 240), 80, (255, 255, 255), -1)\n",
    "cv2.circle(circle_image, (450, 240), 60, (255, 255, 255), -1)\n",
    "\n",
    "gray_circles = cv2.cvtColor(circle_image, cv2.COLOR_BGR2GRAY)\n",
    "gray_circles = cv2.medianBlur(gray_circles, 5)\n",
    "\n",
    "circles = cv2.HoughCircles(gray_circles, cv2.HOUGH_GRADIENT, dp=1, minDist=50,\n",
    "                           param1=50, param2=30, minRadius=10, maxRadius=100)\n",
    "\n",
    "# Draw detected circles\n",
    "result_circles = circle_image.copy()\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for circle in circles[0, :]:\n",
    "        cx, cy, radius = circle\n",
    "        cv2.circle(result_circles, (cx, cy), radius, (0, 255, 0), 2)\n",
    "        cv2.circle(result_circles, (cx, cy), 2, (0, 0, 255), 3)\n",
    "    print(f'Detected {len(circles[0])} circles')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(circle_image)\n",
    "axes[0].set_title('Original')\n",
    "axes[1].imshow(cv2.cvtColor(result_circles, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Detected Circles')\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b345e1f5",
   "metadata": {},
   "source": [
    "## 5. Feature Detection with ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d67e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ORB detector\n",
    "orb = cv2.ORB_create(nfeatures=500)\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
    "\n",
    "print(f'Found {len(keypoints)} keypoints')\n",
    "if descriptors is not None:\n",
    "    print(f'Descriptor shape: {descriptors.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed748d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw keypoints\n",
    "result_orb = cv2.drawKeypoints(image, keypoints, None,\n",
    "                               flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(result_orb, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'ORB Keypoints ({len(keypoints)} detected)')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd537855",
   "metadata": {},
   "source": [
    "## 6. Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a template (small region to find)\n",
    "template = gray[100:200, 100:200]\n",
    "template_h, template_w = template.shape\n",
    "\n",
    "# Perform template matching\n",
    "result_match = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "# Find best match location\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result_match)\n",
    "\n",
    "print(f'Best match confidence: {max_val:.4f}')\n",
    "print(f'Match location: {max_loc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f71b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw rectangle around match\n",
    "top_left = max_loc\n",
    "bottom_right = (top_left[0] + template_w, top_left[1] + template_h)\n",
    "\n",
    "result_template = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "cv2.rectangle(result_template, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Original')\n",
    "axes[1].imshow(template, cmap='gray')\n",
    "axes[1].set_title('Template')\n",
    "axes[2].imshow(result_template)\n",
    "axes[2].set_title(f'Match Found (conf={max_val:.2f})')\n",
    "for ax in axes:\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0129e774",
   "metadata": {},
   "source": [
    "## 7. Face Detection with Haar Cascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ba011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    ")\n",
    "\n",
    "# Load eye detector\n",
    "eye_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + 'haarcascade_eye.xml'\n",
    ")\n",
    "\n",
    "print(\"Haar cascades loaded successfully\")\n",
    "print(f\"Face cascade empty: {face_cascade.empty()}\")\n",
    "print(f\"Eye cascade empty: {eye_cascade.empty()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b28550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple test image (for demonstration)\n",
    "# In practice, you would load an actual face image\n",
    "test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "gray_test = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces\n",
    "faces = face_cascade.detectMultiScale(\n",
    "    gray_test,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    minSize=(30, 30)\n",
    ")\n",
    "\n",
    "print(f'Found {len(faces)} faces')\n",
    "\n",
    "# Draw rectangles around faces\n",
    "result_faces = test_image.copy()\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(result_faces, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    cv2.putText(result_faces, 'Face', (x, y-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "print(\"Face detection complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ddcbbc",
   "metadata": {},
   "source": [
    "## 8. Real-Time Face Detection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_webcam():\n",
    "    \"\"\"\n",
    "    Real-time face detection using webcam.\n",
    "    Press 'q' to quit, 's' to save current frame.\n",
    "    \n",
    "    NOTE: This function requires a webcam and will open a window.\n",
    "    Comment out or skip if running headless.\n",
    "    \"\"\"\n",
    "    face_cascade = cv2.CascadeClassifier(\n",
    "        cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "    )\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print('Error: Could not open webcam')\n",
    "        return\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    frame_count = 0\n",
    "    print('Starting face detection... Press q to quit, s to save frame')\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print('Error: Failed to capture frame')\n",
    "            break\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)\n",
    "        )\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, 'Face', (x, y - 10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        info_text = f'Faces: {len(faces)} | Press q to quit, s to save'\n",
    "        cv2.putText(frame, info_text, (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Face Detection', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('s'):\n",
    "            filename = f'face_detection_{frame_count}.jpg'\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f'Saved {filename}')\n",
    "            frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Face detection completed')\n",
    "\n",
    "# Uncomment to run (requires webcam):\n",
    "# detect_faces_webcam()\n",
    "print(\"Face detection function defined (uncomment to run with webcam)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457dd219",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned:\n",
    "- ✓ Advanced edge detection (Sobel, Laplacian, Canny)\n",
    "- ✓ Contour detection and analysis\n",
    "- ✓ Hough Transform for line and circle detection\n",
    "- ✓ ORB feature detection and matching\n",
    "- ✓ Template matching for object detection\n",
    "- ✓ Haar Cascade face detection\n",
    "- ✓ Real-time webcam applications\n",
    "\n",
    "**Key Takeaway:** Classical CV techniques are fast, interpretable, and still useful for many applications!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
